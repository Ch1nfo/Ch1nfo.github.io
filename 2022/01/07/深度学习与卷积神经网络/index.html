<!DOCTYPE html><html lang="en" theme-mode="dark"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>深度学习与卷积神经网络 | Chinfo's blog</title><link rel="icon" type="image/x-icon" href="/favicon.ico"><script>var config = {"root":"/","search":{"preload":false,"activeHolder":"Enter here","blurHolder":"Search","noResult":"Data \"$0\" not found"},"code":{"codeInfo":"$0 - $1 lines","copy":"code.copy","copyFinish":"code.copyFinish","expand":"code.expand"}}</script><script src="//unpkg.com/mermaid@9.2.2/dist/mermaid.min.js"></script><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lightgallery.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-zoom.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-thumbnail.css"><link type="text/css" rel="stylesheet" href="/lib/fontawesome/css/all.min.css"><link rel="stylesheet" href="/css/arknights.css"><script>if (window.localStorage.getItem('theme-mode') === 'light')
 document.documentElement.setAttribute('theme-mode', 'light')
if (window.localStorage.getItem('theme-mode') === 'dark')
 document.documentElement.setAttribute('theme-mode', 'dark')</script><style>@font-face {
 font-family: Bender;
 src: local('Bender'), url("/font/Bender.ttf"), url("/font/Bender.otf");
}
@font-face {
 font-family: BenderLight;
 src: local('BenderLight'), url("/font/BenderLight.ttf");
}
@font-face {
 font-family: 'JetBrains Mono';
 src: local('JetBrains Mono'), url('/font/JetBrainsMono-Regular.woff2') format('woff2');
}</style><style>:root {
  --dark-background: url('https://ak.hypergryph.com/assets/index/images/ak/pc/bk.jpg');
  --light-background: url('/img/bk.jpg');
}</style><meta name="generator" content="Hexo 6.3.0"></head><body><div class="loading" style="opacity: 0;"><div class="loadingBar left"></div><div class="loadingBar right"></div></div><main><header class="closed"><div class="navBtn"><i class="navBtnIcon"><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span></i></div><nav><div class="navItem" id="search-header"><span class="navItemTitle"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="Search" spellcheck="false" maxlength="50" type="text" id="search-input"></span></div><div class="navItem" id="search-holder"></div><div class="search-popup"><div id="search-result"></div></div><ol class="navContent"><li class="navItem"><a class="navBlock" href="/"><span class="navItemTitle">Home</span></a></li><li class="navItem" matchdata="categories,tags"><a class="navBlock" href="/archives/"><span class="navItemTitle">Archives</span></a></li></ol></nav></header><article><div id="post-bg"><div id="post-title"><h1>深度学习与卷积神经网络</h1><div id="post-info"><span>First Post: <div class="control"><time datetime="2022-01-07T13:54:02.000Z" id="date"> 2022-01-07</time></div></span><br><span>Last Update: <div class="control"><time datetime="2023-09-24T08:43:23.528Z" id="updated"> 2023-09-24</time></div></span></div></div><hr><div id="post-content"><h1 id="深度学习与卷积神经网络"><a href="#深度学习与卷积神经网络" class="headerlink" title="深度学习与卷积神经网络"></a>深度学习与卷积神经网络</h1><h2 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h2><p>深度学习，就是不断增加一个神经网络的隐藏层神经元，让输入的数据被这些神经元不断地抽象和理解，最后得到一个具有泛化能力的预测网络模型。而我们一般把隐藏层超过三层的神经网络称为“深度神经网络”。</p>
<p>我们很难用精确的数学手段去分析网络中的每一个神经元在想什么，我们能做的也就只有对学习率，激活函数，神经元数量等等方面进行更改，并送入数据进行训练，期待最后的结果。</p>
<p>想直观的体验这样的过程tensorflow游乐场是个很好的网站（<a target="_blank" rel="noopener" href="https://playground.tensorflow.org)/">https://playground.tensorflow.org）</a></p>
<p>接下来，我就使用Keras来实现一个简单的深度学习。</p>
<p>这次的散点图就变得更加复杂。</p>
<p class='item-img' data-src='https://cdn.jsdelivr.net/gh/Ch1nfo/picbed@main/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202022-01-07%20094014.png'><img src="https://cdn.jsdelivr.net/gh/Ch1nfo/picbed@main/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202022-01-07%20094014.png"></p>
<p>上下螺旋型的分布使得之前写过的所有模型都不再适合，这时候Keras的强大与便捷便体现了出来。只需要调一调参数，增加隐藏层数量，一个更加强的深度神经网络便形成了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">import dataset<br>import numpy as np<br>import plot_utils<br>from keras.models import Sequential <br>from keras.layers import Dense <br>from tensorflow.keras.optimizers import SGD<br><br>m = 100<br>X, Y = dataset.get_beans(m)<br>plot_utils.show_scatter(X,Y)<br><br>model = Sequential()<br>model.add(Dense(units=8, activation=&#x27;relu&#x27;, input_dim=2))<br>model.add(Dense(units=8, activation=&#x27;relu&#x27;,))<br>model.add(Dense(units=8, activation=&#x27;relu&#x27;,))<br>model.add(Dense(units=1, activation=&#x27;sigmoid&#x27;,))<br><br>model.compile(loss=&#x27;mean_squared_error&#x27;, optimizer=SGD(lr=0.05), metrics=[&#x27;accuracy&#x27;])<br><br>model.fit(X, Y, epochs=5000, batch_size=10)<br><br>pres = model.predict(X)<br><br>plot_utils.show_scatter_surface(X, Y, model)<br></code></pre></td></tr></table></figure>

<p>甚至不需要太多代码就能很好的拟合</p>
<p class='item-img' data-src='https://cdn.jsdelivr.net/gh/Ch1nfo/picbed@main/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202022-01-06%20161953.png'><img src="https://cdn.jsdelivr.net/gh/Ch1nfo/picbed@main/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202022-01-06%20161953.png"></p>
<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><p>在机器学习，神经网络领域，有一个应用层面上的经典的“hello world”。那就是手写体识别。因为它场景简单明确，更有经典的数据集mnist。</p>
<p>mnist数据集里是28*28像素的灰度图，用0到255来代表颜色的深浅。我们要怎样将一张图片送入神经网络进行学习呢？没错，我们把这些像素看成数字就好，这将形成一个最小值为0，最大值为255的(28,28)的矩阵，自然就可以送入学习了。</p>
<p>但是，如果使用全连接神经网络，即使把网络堆叠的越来越深，添加更多的隐藏层，用尽防止过拟合的方法，但泛化能力依旧不尽人意。在深度学习巨头Lecun整理的数据中，效果最好的全连接神经网络是2010年的一个6层的网络，规模已经达到了惊人的2500-2000-1500-1000-500-10，作者也毫不避讳的说到，他们就是硬算，他们有强大的显卡。</p>
<p>但对于卷积神经网络，即使是早在1998年提出的LeNet-5也比6层的全连接神经网络准确率更高。接下来我就用mnist数据集复现一下这个经典的卷积神经网络。</p>
<p>为了体现卷积神经网络的优势，我先用全连接神经网络搭建了一个模型。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">from keras.datasets import mnist<br>import numpy as np<br>from keras.models import Sequential <br>from keras.layers import Dense <br>from tensorflow.keras.optimizers import SGD<br>import matplotlib.pyplot as plt<br>from tensorflow.keras.utils import to_categorical<br><br>(X_train, Y_train), (X_test, Y_test) = mnist.load_data() #均为numpy的ndarray类型<br><br>print(&quot;X_train.shape:&quot;+str(X_train.shape))<br>print(&quot;Y_train.shape:&quot;+str(Y_train.shape))<br>print(&quot;X_test.shape:&quot;+str(X_test.shape))<br>print(&quot;Y_test.shape:&quot;+str(Y_test.shape))<br><br>print(Y_train[0])<br>plt.imshow(X_train[0], cmap=&#x27;gray&#x27;)<br>plt.show()<br><br>X_train = X_train.reshape(60000,784)/255.0<br>X_test = X_test.reshape(10000,784)/255.0<br><br>Y_train = to_categorical(Y_train,10)<br>Y_test = to_categorical(Y_test,10)<br><br>model = Sequential()<br>model.add(Dense(units=256, activation=&#x27;relu&#x27;, input_dim=784))<br>model.add(Dense(units=256, activation=&#x27;relu&#x27;,))<br>model.add(Dense(units=256, activation=&#x27;relu&#x27;,))<br>model.add(Dense(units=10, activation=&#x27;softmax&#x27;,))<br><br>model.compile(loss=&#x27;mean_squared_error&#x27;, optimizer=SGD(lr=0.05), metrics=[&#x27;accuracy&#x27;])<br><br>model.fit(X_train, Y_train, epochs=5000, batch_size=2048)<br><br>pres = model.predict(X)<br><br>plot_utils.show_scatter_surface(X, Y, model)<br></code></pre></td></tr></table></figure>

<p>这是一个256-256-256-10的模型。因为使用的是全连接层，所以我使用reshape()函数将60000<em>28</em>28和10000<em>28</em>28改成了60000<em>784和10000</em>784。又在 X_train 和 X_test 的值后&#x2F;255进行归一化操作，将激活函数改为了更加适合多分类的softmax。运行得到的结果是这样的：</p>
<p class='item-img' data-src='https://cdn.jsdelivr.net/gh/Ch1nfo/picbed@main/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202022-01-07%20161958.png'><img src="https://cdn.jsdelivr.net/gh/Ch1nfo/picbed@main/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202022-01-07%20161958.png"></p>
<p>接下来就是复现 LeNet-5 卷积神经网络了</p>
<p class='item-img' data-src='https://cdn.jsdelivr.net/gh/Ch1nfo/picbed@main/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202022-01-07%20104447.png'><img src="https://cdn.jsdelivr.net/gh/Ch1nfo/picbed@main/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202022-01-07%20104447.png"></p>
<p>由架构图可以看到，在第一个卷积层，32<em>32的图片被卷成了6个28</em>28的，当然卷积核就是6个5<em>5的，步长为1。但由于mnist数据集本身就是28</em>28的图片，所以实现时会有行一些改变。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">model.add(Conv2D(filters=6, kernel_size=(5,5), strides=(1,1), input_shape=(28, 28, 1), padding=&#x27;valid&#x27;, activation=&#x27;relu&#x27;))<br></code></pre></td></tr></table></figure>

<p>之后是第一个池化层， LeNet-5使用的是2*2的平均池化。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">model.add(AveragePooling2D(pool_size=(2,2)))<br></code></pre></td></tr></table></figure>

<p>之后是第二个卷积层。它使用16个5*5的卷积核</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), padding=&#x27;valid&#x27;, activation=&#x27;relu&#x27;))<br></code></pre></td></tr></table></figure>

<p>之后是第二个相同的池化层。我们需要把最后这个池化层的输出平铺成一个数组。使用Keras的Flatten实现</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">model.add(Flatten())<br></code></pre></td></tr></table></figure>

<p>后面的就是全连接层了。由架构图可以看到，最后是个120-84-10的全连接层</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">model.add(Dense(units=120, activation=&#x27;relu&#x27;))<br>model.add(Dense(units=84, activation=&#x27;relu&#x27;))<br>model.add(Dense(units=10, activation=&#x27;softmax&#x27;))<br></code></pre></td></tr></table></figure>

<p>这样， LeNet-5 网络就搭建好了。之后将mnist数据集送入训练并评估</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">model.compile(loss=&#x27;mean_squared_error&#x27;, optimizer=SGD(lr=0.05), metrics=[&#x27;accuracy&#x27;])<br>model.fit(X_train, Y_train, epochs=5000, batch_size=2048)<br><br>pres = model.predict(X)<br>plot_utils.show_scatter_surface(X, Y, model)<br></code></pre></td></tr></table></figure>

<p>最后得到这样的结果</p>
<p class='item-img' data-src='https://cdn.jsdelivr.net/gh/Ch1nfo/picbed@main/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202022-01-07%20160439.png'><img src="https://cdn.jsdelivr.net/gh/Ch1nfo/picbed@main/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202022-01-07%20160439.png"></p>
<p>很明显可以看出是比全连接神经网络更好的。</p>
<div id="paginator"></div></div><div id="post-footer"><div id="pages"><div class="footer-link" style="width: 50%;text-align:right;border-right:1px #fe2 solid"><a href="/2022/01/08/%E5%BA%8F%E5%88%97%E4%BE%9D%E8%B5%96%E9%97%AE%E9%A2%98%E2%80%94%E2%80%94%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/">← Next 序列依赖问题——文本情感分类</a></div><div class="footer-link" style="width: 50%;right:1px;border-left:1px #fe2 solid"><a href="/2022/01/06/%E6%95%B0%E7%BB%84%E7%9A%84%E5%88%A9%E7%94%A8%E4%B8%8E%E5%88%9D%E8%AF%86Keras/">数组的利用与初识Keras Prev →</a></div></div></div></div><div class="bottom-btn"><div><a class="i-top" id="to-top" onClick="scrolls.scrolltop();" title="To Top" style="opacity: 0; display: none;">∧ </a><a class="i-index" id="to-index" href="#toc-div" title="To Catalog">≡</a><a class="i-color" id="color-mode" onClick="colorMode.change()" title="Change Theme"></a></div></div></article><aside><div id="about"><a href="/" id="logo"><img src="https://ak.hypergryph.com/assets/index/images/ak/pc/faction/1.png" alt="Logo"></a><h1 id="Dr"><a href="/">Chinfo's Blog</a></h1><div id="description"><p></p></div><div id="social-links"><a class="social" target="_blank" rel="noopener" href="https://github.com/Ch1nfo"><i class="fab fa-github" alt="GitHub"></i></a></div></div><div id="aside-block"><div id="toc-div"><h1>Catalog</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">深度学习与卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.1.</span> <span class="toc-text">深度学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.2.</span> <span class="toc-text">卷积神经网络</span></a></li></ol></li></ol></div></div><footer><nobr>Published with <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a></nobr><wbr><nobr> Theme <a target="_blank" rel="noopener" href="https://github.com/Yue-plus/hexo-theme-arknights">Arknights</a></nobr><wbr><nobr> by <a target="_blank" rel="noopener" href="https://github.com/Yue-plus">Yue_plus</a></nobr></footer></aside></main><canvas id="canvas-dust"></canvas><script src="/js/search.js"></script><script src="/js/arknights.js"></script><script src="//unpkg.com/lightgallery@2.7.1/lightgallery.min.js"></script><script src="//unpkg.com/lightgallery@2.7.1/plugins/zoom/lg-zoom.min.js"></script><script src="//unpkg.com/lightgallery@2.7.1/plugins/thumbnail/lg-thumbnail.min.js"></script><script src="/js/pjax.js"></script><script class="pjax-js">reset= () => {document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);reset()})</script></body></html>