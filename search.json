[{"title":"激活函数","url":"/2022/01/04/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/","content":"之前对于一个函数的精确拟合的方式，对于一个智能体来说比较罕见，我们更多的是判断一个一个东西对，或者不对，最多再多一个不确定。这样的判断方式自然就和先前的拟合函数的方法相差甚远。为了达到这样的效果，我们便使用激活函数对之前的预测模型进行分类。而到此，我们才真正接触到了完整的Rosenblatt感知器模型。\n为了进行分类，我们自然一开始就想到分段函数。但是这种函数在代码的层面上比较难以实现，所以，我们便引入了Logistic函数。\n\n当然，我们一般取它的标准形式，即：\n\n对于这样的函数我们可以使用nupmy库的exp()函数来实现：1&#x2F;(1+np.exp(-y))。\n这样我们便可以使用它来对预测结果进行分类了\n利用复合函数求导的知识，对加入了激活函数的预测函数求偏导数。\n              deda = -2*(y-a)dadz = a*(1-a)dzdw = xdedw = deda*dadz*dzdwdzdb = 1dedb = deda*dadz*dzdb\n\n再把这段代码加入之前的代码，在进行一些修改，我们可以得到最后的源码：\nimport datasetimport matplotlib.pyplot as pltimport numpy as npxs, ys = dataset.get_beans(100)print(xs)print(ys)plt.title(&quot;STF&quot;, fontsize=12)plt.xlabel(&quot;B&quot;)plt.ylabel(&quot;T&quot;)plt.scatter(xs, ys)w = 0.1b = 0.1y_pre = w*xs + bplt.plot(xs, y_pre)plt.show()for _ in range(5000):\tfor i in range(100):\t\tx = xs[i]\t\ty = ys[i]\t\t\t\tz = w*x + b\t\ta = 1/(1+np.exp(-z))\t\te = (y-a)**2\t\tdeda = -2*(y-a)\t\tdadz = a*(1-a)\t\tdzdw = x\t\tdedw = deda*dadz*dzdw\t\tdzdb = 1\t\tdedb = deda*dadz*dzdb\t\talpha = 0.05\t\tw = w - alpha*dedw\t\tb = b - alpha*dedb\tif _%100 == 0:\t\tplt.clf()\t\tplt.scatter(xs, ys)\t\tz = w*xs + b\t\ta = 1/(1+np.exp(-z))\t\tplt.xlim(0,1)\t\tplt.ylim(0,1.2)\t\tplt.plot(xs, a)\t\tplt.pause(0.01)#暂停0.01秒\n\n运行后可以观察到：\n很好的对两类数据进行了分类。\n","categories":["AIlearning"],"tags":["AI"]},{"title":"深度学习与卷积神经网络","url":"/2022/01/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","content":"深度学习深度学习，就是不断增加一个神经网络的隐藏层神经元，让输入的数据被这些神经元不断地抽象和理解，最后得到一个具有泛化能力的预测网络模型。而我们一般把隐藏层超过三层的神经网络称为“深度神经网络”。\n我们很难用精确的数学手段去分析网络中的每一个神经元在想什么，我们能做的也就只有对学习率，激活函数，神经元数量等等方面进行更改，并送入数据进行训练，期待最后的结果。\n想直观的体验这样的过程tensorflow游乐场是个很好的网站（https://playground.tensorflow.org）\n接下来，我就使用Keras来实现一个简单的深度学习。\n这次的散点图就变得更加复杂。\n\n上下螺旋型的分布使得之前写过的所有模型都不再适合，这时候Keras的强大与便捷便体现了出来。只需要调一调参数，增加隐藏层数量，一个更加强的深度神经网络便形成了。\nimport datasetimport numpy as npimport plot_utilsfrom keras.models import Sequential from keras.layers import Dense from tensorflow.keras.optimizers import SGDm = 100X, Y = dataset.get_beans(m)plot_utils.show_scatter(X,Y)model = Sequential()model.add(Dense(units=8, activation=&#x27;relu&#x27;, input_dim=2))model.add(Dense(units=8, activation=&#x27;relu&#x27;,))model.add(Dense(units=8, activation=&#x27;relu&#x27;,))model.add(Dense(units=1, activation=&#x27;sigmoid&#x27;,))model.compile(loss=&#x27;mean_squared_error&#x27;, optimizer=SGD(lr=0.05), metrics=[&#x27;accuracy&#x27;])model.fit(X, Y, epochs=5000, batch_size=10)pres = model.predict(X)plot_utils.show_scatter_surface(X, Y, model)\n\n甚至不需要太多代码就能很好的拟合\n\n卷积神经网络在机器学习，神经网络领域，有一个应用层面上的经典的“hello world”。那就是手写体识别。因为它场景简单明确，更有经典的数据集mnist。\nmnist数据集里是28*28像素的灰度图，用0到255来代表颜色的深浅。我们要怎样将一张图片送入神经网络进行学习呢？没错，我们把这些像素看成数字就好，这将形成一个最小值为0，最大值为255的(28,28)的矩阵，自然就可以送入学习了。\n但是，如果使用全连接神经网络，即使把网络堆叠的越来越深，添加更多的隐藏层，用尽防止过拟合的方法，但泛化能力依旧不尽人意。在深度学习巨头Lecun整理的数据中，效果最好的全连接神经网络是2010年的一个6层的网络，规模已经达到了惊人的2500-2000-1500-1000-500-10，作者也毫不避讳的说到，他们就是硬算，他们有强大的显卡。\n但对于卷积神经网络，即使是早在1998年提出的LeNet-5也比6层的全连接神经网络准确率更高。接下来我就用mnist数据集复现一下这个经典的卷积神经网络。\n为了体现卷积神经网络的优势，我先用全连接神经网络搭建了一个模型。\nfrom keras.datasets import mnistimport numpy as npfrom keras.models import Sequential from keras.layers import Dense from tensorflow.keras.optimizers import SGDimport matplotlib.pyplot as pltfrom tensorflow.keras.utils import to_categorical(X_train, Y_train), (X_test, Y_test) = mnist.load_data() #均为numpy的ndarray类型print(&quot;X_train.shape:&quot;+str(X_train.shape))print(&quot;Y_train.shape:&quot;+str(Y_train.shape))print(&quot;X_test.shape:&quot;+str(X_test.shape))print(&quot;Y_test.shape:&quot;+str(Y_test.shape))print(Y_train[0])plt.imshow(X_train[0], cmap=&#x27;gray&#x27;)plt.show()X_train = X_train.reshape(60000,784)/255.0X_test = X_test.reshape(10000,784)/255.0Y_train = to_categorical(Y_train,10)Y_test = to_categorical(Y_test,10)model = Sequential()model.add(Dense(units=256, activation=&#x27;relu&#x27;, input_dim=784))model.add(Dense(units=256, activation=&#x27;relu&#x27;,))model.add(Dense(units=256, activation=&#x27;relu&#x27;,))model.add(Dense(units=10, activation=&#x27;softmax&#x27;,))model.compile(loss=&#x27;mean_squared_error&#x27;, optimizer=SGD(lr=0.05), metrics=[&#x27;accuracy&#x27;])model.fit(X_train, Y_train, epochs=5000, batch_size=2048)pres = model.predict(X)plot_utils.show_scatter_surface(X, Y, model)\n\n这是一个256-256-256-10的模型。因为使用的是全连接层，所以我使用reshape()函数将600002828和100002828改成了60000784和10000784。又在 X_train 和 X_test 的值后&#x2F;255进行归一化操作，将激活函数改为了更加适合多分类的softmax。运行得到的结果是这样的：\n\n接下来就是复现 LeNet-5 卷积神经网络了\n\n由架构图可以看到，在第一个卷积层，3232的图片被卷成了6个2828的，当然卷积核就是6个55的，步长为1。但由于mnist数据集本身就是2828的图片，所以实现时会有行一些改变。\nmodel.add(Conv2D(filters=6, kernel_size=(5,5), strides=(1,1), input_shape=(28, 28, 1), padding=&#x27;valid&#x27;, activation=&#x27;relu&#x27;))\n\n之后是第一个池化层， LeNet-5使用的是2*2的平均池化。\nmodel.add(AveragePooling2D(pool_size=(2,2)))\n\n之后是第二个卷积层。它使用16个5*5的卷积核\nmodel.add(Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), padding=&#x27;valid&#x27;, activation=&#x27;relu&#x27;))\n\n之后是第二个相同的池化层。我们需要把最后这个池化层的输出平铺成一个数组。使用Keras的Flatten实现\nmodel.add(Flatten())\n\n后面的就是全连接层了。由架构图可以看到，最后是个120-84-10的全连接层\nmodel.add(Dense(units=120, activation=&#x27;relu&#x27;))model.add(Dense(units=84, activation=&#x27;relu&#x27;))model.add(Dense(units=10, activation=&#x27;softmax&#x27;))\n\n这样， LeNet-5 网络就搭建好了。之后将mnist数据集送入训练并评估\nmodel.compile(loss=&#x27;mean_squared_error&#x27;, optimizer=SGD(lr=0.05), metrics=[&#x27;accuracy&#x27;])model.fit(X_train, Y_train, epochs=5000, batch_size=2048)pres = model.predict(X)plot_utils.show_scatter_surface(X, Y, model)\n\n最后得到这样的结果\n\n很明显可以看出是比全连接神经网络更好的。\n","categories":["AIlearning"],"tags":["AI"]},{"title":"数组的利用与初识Keras","url":"/2022/01/06/%E6%95%B0%E7%BB%84%E7%9A%84%E5%88%A9%E7%94%A8%E4%B8%8E%E5%88%9D%E8%AF%86Keras/","content":"在之前的学习中我一直使用的是方程的形式进行前向传播梯度下降与反向传播。然而随着输入参数与隐藏层的增多，方程形式似乎不再能胜任如此复杂的工作，这时候就需要引入另一个数学工具——矩阵。\nnumpy库是一个强大的数学计算库，使用它可以让矩阵的计算变得简单许多。\n这是利用方程的代码：\nw1 = 0.1w2 = 0.1b = 0.1x1s = xs[:,0]#切割第0列形成一个新的数组x2s = xs[:,1]def forward(x1s,x2s):\tz = w1*x1s + w2*x2s + b\ta = 1/(1+np.exp(-z))\treturn aplot_utils.show_scatter_surface(xs,ys,forward)for _ in range(500):\tfor i in range(m):\t\tx = xs[i]\t\ty = ys[i]\t\tx1 = x[0]\t\tx2 = x[1]\t\ta = forward(x1,x2)\t\te = (y-a)**2\t\tdeda = -2*(y-a)\t\tdadz = a*(1-a)\t\tdzdw1 = x1\t\tdzdw2 = x2\t\tdzdb = 1\t\tdedw1 = deda*dadz*dzdw1\t\tdedw2 = deda*dadz*dzdw2\t\tdedb = deda*dadz*dzdb\t\talpha = 0.01\t\tw1 = w1 - alpha*dedw1\t\tw2 = w2 - alpha*dedw2\t\tb = b - alpha*dedb\n\n这是利用数组的代码：\nW = np.array([0.1, 0.1])B = np.array([0.1])def forward(X):\tZ = X.dot(W.T) + B\tA = 1/(1+np.exp(-Z))\treturn Aplot_utils.show_scatter_surface(X,Y,forward)for _ in range(500):\tfor i in range(m):\t\tXi = X[i]\t\tYi = Y[i]\t\tA = forward(Xi)\t\tE = (Yi-A)**2\t\tdEdA = -2*(Yi-A)\t\tdAdZ = A*(1-A)\t\tdZdW = Xi\t\tdZdB = 1\t\tdEdW = dEdA*dAdZ*dZdW\t\tdEdB = dEdA*dAdZ*dZdB\t\talpha = 0.01\t\tW = W - alpha*dEdW\t\tB = B - alpha*dEdB\n\n可以很直观的发现，使用数组（矩阵）时，代码量会少很多。并且面对越多的输入与隐藏层时，它的优势就会越明显。\n当然，它的拟合度也非常的好。\n\n但是，在面对更加复杂的机器学习，比如卷积神经网络，使用这种编写底层代码的方式将会是个大工程。这时候，Keras就自然而然的进入了我的视野，正如它官网上那样：你恰好发现了Keras\n\n现在，是时候走出对神经网络底层知识的学习，开始进入应用层的大门了。\n为了展现出Keras相较于手撸底层代码的优势，我使用了新的数据集\n\n想要拟合这个数据集无疑会很繁琐，相较于上一个，它又增加了新的隐藏层，这样反向传播的求导过程将十分复杂，但使用Keras后，一切都简单了起来。\nimport datasetimport numpy as npimport plot_utilsfrom keras.models import Sequential from keras.layers import Dense from tensorflow.keras.optimizers import SGDm = 100X, Y = dataset.get_beans4(m)plot_utils.show_scatter(X,Y)model = Sequential()model.add(Dense(units=2, activation=&#x27;sigmoid&#x27;, input_dim=2))model.add(Dense(units=1, activation=&#x27;sigmoid&#x27;,))model.compile(loss=&#x27;mean_squared_error&#x27;, optimizer=SGD(lr=0.05), metrics=[&#x27;accuracy&#x27;])model.fit(X, Y, epochs=5000, batch_size=10)pres = model.predict(X)plot_utils.show_scatter_surface(X, Y, model)\n\n只需要小小的改一个数字就能增加隐藏层，这实在是太方便了。\n\n效果也是非常的好\n","categories":["AIlearning"],"tags":["AI"]},{"title":"简单的Rosenblatt感知器与二维方差代价函数","url":"/2022/01/02/%E7%AE%80%E5%8D%95%E7%9A%84Rosenblatt%E6%84%9F%E7%9F%A5%E5%99%A8%E4%B8%8E%E4%BA%8C%E7%BB%B4%E6%96%B9%E5%B7%AE%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0/","content":"简单的Rosenblatt感知器为了使得到的数据更加直观，我使用了python的matplotlib绘制图像\n首先写一个可以获取散点的函数\nimport numpy as npdef get_beans(counts):\txs = np.random.rand(counts)\txs = np.sort(xs)\tys = [1.2*x+np.random.rand()/10 for x in xs]\treturn xs,ys\n\n调用它并使其在坐标系中打印出来\nimport datasetfrom matplotlib import pyplot as pltxs,ys=dataset.get_beans(100)print(xs)print(ys)plt.title(&quot;STF&quot;,fontsize=12)plt.xlabel(&quot;B&quot;)plt.ylabel(&quot;T&quot;)plt.scatter(xs,ys)\n\n我们可以得到这样的一个图像\n\n之后任意设定一个权重值w为0.1\n用标准答案减去该参数计算得到的结果得到一个误差，用原来的w加上alpha误差B（乘B是为了应对B为负数时，可能导致结果正好相反的情况，学习率alpha是为了控制调整的幅度，以免幅度过大错过最佳点）作为新的w，再一次进行运算。通过误差修正参数，这就是Rosenblatt感知器的学习过程。当然，这个公式在数学上是收敛的，Novikoff（1962）证明如果训练集是线性分隔的，那么感知器算法可以在有限次迭代后收敛，然而，如果训练集不是线性分隔的，那么这个算法则不能确保会收敛。以下代码简单的实现了 Rosenblatt感知器的学习过程 。\nimport datasetimport numpyfrom matplotlib import pyplot as pltxs, ys = dataset.get_beans(100)print(xs)print(ys)plt.title(&quot;STF&quot;, fontsize=12)plt.xlabel(&quot;B&quot;)plt.ylabel(&quot;T&quot;)plt.scatter(xs, ys)w = 0.5for m in range(100):\tfor i in range(100):\t\tx = xs[i]\t\ty = ys[i]\t\ty_pre = w * x\t\te = y - y_pre\t\talpha = 0.05\t\tw = w + alpha * e * xy_pre = w * xsprint(y_pre)plt.plot(xs, y_pre)plt.show()\n\n这样，运行后就可以得到一条与散点拟合的线\n\n之后任意设定一个权重值w为0.1\n用标准答案减去该参数计算得到的结果得到一个误差，用原来的w加上alpha误差B（乘B是为了应对B为负数时，可能导致结果正好相反的情况，学习率alpha是为了控制调整的幅度，以免幅度过大错过最佳点）作为新的w，再一次进行运算。通过误差修正参数，这就是Rosenblatt感知器的学习过程。当然，这个公式在数学上是收敛的，Novikoff（1962）证明如果训练集是线性分隔的，那么感知器算法可以在有限次迭代后收敛，然而，如果训练集不是线性分隔的，那么这个算法则不能确保会收敛。以下代码简单的实现了 Rosenblatt感知器的学习过程 。\nimport datasetimport numpyfrom matplotlib import pyplot as pltxs, ys = dataset.get_beans(100)print(xs)print(ys)plt.title(&quot;STF&quot;, fontsize=12)plt.xlabel(&quot;B&quot;)plt.ylabel(&quot;T&quot;)plt.scatter(xs, ys)w = 0.5for m in range(100):\tfor i in range(100):\t\tx = xs[i]\t\ty = ys[i]\t\ty_pre = w * x\t\te = y - y_pre\t\talpha = 0.05\t\tw = w + alpha * e * xy_pre = w * xsprint(y_pre)plt.plot(xs, y_pre)plt.show()\n\n这样，运行后就可以得到一条与散点拟合的线\n方差代价函数 Rosenblatt感知器 其本身在现代神经网络研究中已经并不常用了，但我们依旧能从其中学习到参数的自适应调整是一个人工神经元的精髓。\n我们可以使用方差代价函数来评估误差从而达到参数的自适应调整。此时我们再次随便设定一个w，用统计到的数据去评估w的准确性，即回归分析。而我们可以使用最小二乘法来实现。我们将w作为自变量，误差e作为因变量，得到一个新的函数，即代价函数。他展现出当w取不同值时对于环境中问题数据进行预测时产生的误差e。因为他是一个二次函数，我们就可以利用它的最低点的w（此时e最小）带回预测函数，以此实现对参数w的自适应调整。\n在之前代码的基础上进行修改，我们可以得到下面的代码\nimport datasetimport matplotlib.pyplot as pltimport numpy as npxs, ys = dataset.get_beans(100)print(xs)print(ys)plt.title(&quot;STF&quot;, fontsize=12)plt.xlabel(&quot;B&quot;)plt.ylabel(&quot;T&quot;)plt.scatter(xs, ys)w = 0.1 # 可以任意y_pre = w*xsplt.plot(xs, y_pre)plt.show()es = (ys-y_pre)**2 sum_e = np.sum(es)sum_e = (1/100)*sum_eprint(sum_e)ws = np.arange(0,3,0.1)# 从0到3每次增加0.1es = []for w in ws:\ty_pre = w*xs\te = (1/100)*np.sum(ys-y_pre)**2\tes.append(e)# 设定代价函数坐标系plt.title(&quot;cost&quot;, fontsize=12)plt.xlabel(&quot;w&quot;)plt.ylabel(&quot;e&quot;)plt.plot(ws,es)plt.show()w_min = np.sum(xs*ys)/np.sum(xs*xs)print(&quot;eminw:&quot;+str(w_min))y_pre = w_min*xsplt.title(&quot;STF&quot;, fontsize=12)plt.xlabel(&quot;B&quot;)plt.ylabel(&quot;T&quot;)plt.scatter(xs, ys)plt.plot(xs, y_pre)plt.show()\n\n运行后得到三幅图\n\n\n","categories":["AIlearning"],"tags":["AI"]},{"title":"序列依赖问题——文本情感分类","url":"/2022/01/08/%E5%BA%8F%E5%88%97%E4%BE%9D%E8%B5%96%E9%97%AE%E9%A2%98%E2%80%94%E2%80%94%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/","content":"之前的LeNet-5卷积神经网络模型体现了数据在空间上的关联性，但除此之外，数据也有可能在时间上有关联性，比如气温数据，股票数据等。当然，最典型的还是人类的语言。面对这样在时间上有关联的数据，神经网络该如何去识别和处理呢？\n我们一般把词作为自然语言处理的基本单位，这样就可以利用“词典”用一个数字来代表一个词，这个数字就是索引值。这样，由词组成的一句话就会转化为一个由数字组成的向量，自然就可以送入神经网络进行识别了。\n如果有些词在词典中由于种种原因数据接近，但是含义却相差甚远，这时候如果再进行归一化操作，计算机就很可能错误的识别到完全相反的意思。这样的数据就会给预测模型带来不必要的麻烦。所以我们可以使用one-hot的编码方式对词汇进行编码。通过one-hot编码后每个词都完全不一样。\n但是这样进行严格区分的话，又丢失了词汇的关联性。我们可以提取出一个词汇的多个特征值形成一个词向量，即NLP中的词嵌入。\n最后我们结合一下one-hot和词向量。让词向量组成的矩阵（字典）点乘按词语组成句子的one-hot编码形成的矩阵，这样就可以提取出句子中每一个词的词向量，这样就可以送入神经网络进行学习了。\n明白了原理，我们就来实现一个简单的文本情感分类模型\n首先在网上找到了一个别人爬的网购评论的csv文件，然后封装一个shoppingdata.py用来读取和处理这些数据。\nimport osimport kerasimport numpy as npimport keras.preprocessing.text as textimport reimport jiebaimport randomdef load_data():\txs = []\tys = []\twith open(os.path.dirname(os.path.abspath(__file__))+&#x27;/online_shopping_10_cats.csv&#x27;,&#x27;r&#x27;,encoding=&#x27;utf-8&#x27;) as f:\t\tline=f.readline()#escape first line&quot;label review&quot;\t\twhile line:\t\t\tline=f.readline()\t\t\tif not line:\t\t\t\tbreak\t\t\tcontents = line.split(&#x27;,&#x27;)\t\t\t# if contents[0]==&quot;书籍&quot;:\t\t\t# \tcontinue\t\t\tlabel = int(contents[1])\t\t\treview = contents[2]\t\t\tif len(review)&gt;20:\t\t\t\tcontinue\t\t\txs.append(review)\t\t\tys.append(label)\txs = np.array(xs)\tys = np.array(ys)\t#打乱数据集\tindies = [i for i in range(len(xs))] \trandom.seed(666)\trandom.shuffle(indies)\txs = xs[indies]\tys = ys[indies]\tm = len(xs)\tcutpoint = int(m*4/5)\tx_train = xs[:cutpoint]\ty_train = ys[:cutpoint]\tx_test = xs[cutpoint:]\ty_test = ys[cutpoint:]\t\tprint(&#x27;总样本数量:%d&#x27; % (len(xs)))\tprint(&#x27;训练集数量:%d&#x27; % (len(x_train)))\tprint(&#x27;测试集数量:%d&#x27; % (len(x_test)))\treturn x_train,y_train,x_test,y_testdef createWordIndex(x_train,x_test):\tx_all = np.concatenate((x_train,x_test),axis=0)\t#建立词索引\ttokenizer = text.Tokenizer()\t#create word index\tword_dic = &#123;&#125;\tvoca = []\tfor sentence in x_all:\t    # 去掉标点\t    sentence = re.sub(&quot;[\\s+\\.\\!\\/_,$%^*(+\\&quot;\\&#x27;]+|[+——！，。？、~@#￥%……&amp;*（）]+&quot;, &quot;&quot;, sentence)\t    # 结巴分词\t    cut = jieba.cut(sentence)\t    #cut_list = [ i for i in cut ]\t    for word in cut:\t    \tif not (word in word_dic):\t    \t\tword_dic[word]=0\t    \telse:\t    \t\tword_dic[word] +=1\t    \tvoca.append(word)\tword_dic = sorted(word_dic.items(), key = lambda kv:kv[1],reverse=True)\tvoca = [v[0] for v in word_dic]\t\ttokenizer.fit_on_texts(voca)\tprint(&quot;voca:&quot;+str(len(voca)))\treturn len(voca),tokenizer.word_indexdef word2Index(words,word_index):\tvecs = []\tfor sentence in words:\t    # 去掉标点\t    sentence = re.sub(&quot;[\\s+\\.\\!\\/_,$%^*(+\\&quot;\\&#x27;]+|[+——！，。？、~@#￥%……&amp;*（）]+&quot;, &quot;&quot;, sentence)\t    # 结巴分词\t    cut = jieba.cut(sentence)\t    #cut_list = [ i for i in cut ]\t    index=[]\t    for word in cut:\t    \tif word in word_index:\t    \t\tindex.append(float(word_index[word]))\t    # if len(index)&gt;25:\t    # \tindex = index[0:25]\t    vecs.append(np.array(index))\treturn np.array(vecs)\n\n首先得到数据的索引表示：\nx_train_index = shopping_data.word2Index(x_train, word_index)x_test_index = shopping_data.word2Index(x_test, word_index)\n\n因为每句话长短不同，我们需要利用keras.preprocessing中的sequence进行一个对齐操作\nmaxlen = 25x_train_index = sequence.pad_sequences(x_train_index, maxlen=maxlen)x_test_index = sequence.pad_sequences(x_test_index, maxlen=maxlen)\n\n首先创造一个Sequential模型，堆叠Embedding层，然后利用Flatten把数据平铺开，再送入一个256-256-256的神经网络中进行训练，最后利用sigmoid函数进行输出。\nmodel = Sequential()model.add(Embedding(trainable=Ture, input_dim=vocalen, output_dim=300, input_length=maxlen))model.add(Flatten())model.add(Dense(256, activation=&#x27;relu&#x27;))model.add(Dense(256, activation=&#x27;relu&#x27;))model.add(Dense(256, activation=&#x27;relu&#x27;))model.add(Dense(1, activation=&#x27;sigmoid&#x27;))\n\n然后使用交叉熵代价函数和adam优化器，训练200回合，批尺寸为512。\nmodel.compile(loss=&#x27;binary_crossentropy&#x27;,               optimizer=&#x27;adam&#x27;,              metrics=[&#x27;accuracy&#x27;])model.fit(x_train_index, y_train,\t\t  batch_size=512,\t\t  epochs=200)\n\n然后开始训练。得到评估结果。\n\n86%的准确度。\n","categories":["AIlearning"],"tags":["AI"]},{"title":"简单的梯度下降算法实现","url":"/2022/01/03/%E7%AE%80%E5%8D%95%E7%9A%84%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/","content":"二维梯度下降之前使用的算法是一次性计算出结果，在样本数量比较少的情况下还好，在样本较多的情况下，机器的算力可能不足以快速的计算出结果，这时候就需要使用梯度下降算法，我们先从简单的二维开始，即拟合y&#x3D;wx。\n首先依旧是获取散点，绘制坐标系，预设一个w值为0.1\nimport datasetimport matplotlib.pyplot as pltimport numpy as npxs, ys = dataset.get_beans(100)print(xs)print(ys)plt.title(&quot;STF&quot;, fontsize=12)plt.xlabel(&quot;B&quot;)plt.ylabel(&quot;T&quot;)plt.scatter(xs, ys)w = 0.1y_pre = w*xsplt.plot(xs, y_pre)plt.show()\n\n这次写的是随机梯度下降算法，它的原理简单来说就是计算代价函数（w，e）在某一点的导数，用先前的w值减去学习率*斜率。因为在最低点右边时，斜率大于零，减去后向最低点靠拢，在左边时同理。学习率alpha的功能也是控制震荡幅度。这就是梯度下降。而随机指的是每次随机取样本中的一个数据验证拟合度，以避免在大量样本数时算力不足的情况\n它的代码实现很简单，我在这里使用plt.clf()函数和plt.pause()函数相结合来实现动态图像，使拟合过程更加生动形象。\nfor _ in range(100):\tfor i in range(100):\t\tx = xs[i]\t\ty = ys[i]\t\tk = 2*(x**2)*w + (-2*x*y)\t\talpha = 0.05\t\tw = w - alpha*k\t\tplt.clf()\t\tplt.scatter(xs, ys)\t\ty_pre = w*xs\t\tplt.xlim(0,1)\t\tplt.ylim(0,1.2)\t\tplt.plot(xs, y_pre)\t\tplt.pause(0.01)#暂停0.01秒\n\n\n这样就实现了一个二维的随机梯度下降\n三维梯度下降前面实现的二维梯度下降的算法比简单，但是不是所有的图像都会经过坐标原点，这时候w与e的函数便不再适用。完全的一次函数y&#x3D;wx+b需要我们绘制w，e，b的三维代价函数，来求这个三维图像的最低点，这时候，我们便需要使用三维梯度下降。\n首先我们先来绘制三维的代价函数图像，可以使用matplotlib中的Axed3D来实现。\nimport datasetimport matplotlib.pyplot as pltimport numpy as npfrom mpl_toolkits.mplot3d import Axes3Dm=100xs, ys = dataset.get_beans(m)plt.title(&quot;STF&quot;, fontsize=12)plt.xlabel(&quot;B&quot;)plt.ylabel(&quot;T&quot;)plt.xlim(0,1)plt.ylim(0,1.5)plt.scatter(xs, ys)w = 0.1b = 0.1y_pre = w*xs + bplt.plot(xs,y_pre)plt.show()fig = plt.figure()ax = Axes3D(fig)ax.set_zlim(0,2)ws = np.arange(-1,2,0.1)bs = np.arange(-2,2,0.04)for b in bs:\tes = []\tfor w in ws:\t\ty_pre = w*xs + b\t\te = np.sum((ys-y_pre)**2)*(1/m)\t\tes.append(e)\tax.plot(ws,es,b,zdir=&#x27;y&#x27;)plt.show()\n\n\n我们可以清晰地看到它有一个最低点，接下来我们就使用梯度下降算法得到它。\ndw = 2*(x**2)*w + 2*x*b - 2*x*ydb = 2*b + 2*x*w -2*yalpha = 0.05w = w - alpha*dwb = b - alpha*db\n\n分别求得w和b方向上的斜率，把它们合到一起便实现了一次三维梯度下降\n接下来就再用动态图像来观察三位梯度下降的过程，完整代码如下：\nimport datasetimport matplotlib.pyplot as pltimport numpy as npxs, ys = dataset.get_beans(100)print(xs)print(ys)plt.title(&quot;STF&quot;, fontsize=12)plt.xlabel(&quot;B&quot;)plt.ylabel(&quot;T&quot;)plt.scatter(xs, ys)w = 0.1b = 0.1y_pre = w*xs + bplt.plot(xs, y_pre)plt.show()for _ in range(500):\tfor i in range(100):\t\tx = xs[i]\t\ty = ys[i]\t\tdw = 2*(x**2)*w + 2*x*b - 2*x*y\t\tdb = 2*b + 2*x*w -2*y\t\talpha = 0.01\t\tw = w - alpha*dw\t\tb = b - alpha*db\tplt.clf()\tplt.scatter(xs, ys)\ty_pre = w*xs + b\tplt.xlim(0,1)\tplt.ylim(0,1.2)\tplt.plot(xs, y_pre)\tplt.pause(0.01)#暂停0.01秒\n\n最后能得到这样的效果\n\n","categories":["AIlearning"],"tags":["AI"]},{"title":"高维空间——面对多个输入的问题","url":"/2022/01/05/%E9%AB%98%E7%BB%B4%E7%A9%BA%E9%97%B4%E2%80%94%E2%80%94%E9%9D%A2%E5%AF%B9%E5%A4%9A%E4%B8%AA%E8%BE%93%E5%85%A5%E7%9A%84%E9%97%AE%E9%A2%98/","content":"之前我已经讨论了从多个方面观察事物的问题，最后使用增加隐藏层来实现。但至始至终，我都只考虑了一个输入的情况，这也是之前的所有结果均可以在一个平面直角坐标系中画出。而现在，我们来考虑有多个输入的情况，这时，得到的结果便不再是一个平面图像了。\n自然，为了更直观的看到最终拟合的状态，我们需要画一个图。我单独封装了一个plot_utils.py，这样直接import，在需要时就可以直接调用其中的函数。\nimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3Dimport numpy as npdef show_scatter(xs,y):\tx = xs[:,0]\tz = xs[:,1]\tfig = plt.figure()\tax = Axes3D(fig)\tax.scatter(x, z, y)\tplt.show()def show_surface(x,z,forward_propgation):\tx = np.arange(np.min(x),np.max(x),0.1)\tz = np.arange(np.min(z),np.max(z),0.1)\tx,z = np.meshgrid(x,z)\ty = forward_propgation(x,z)\tfig = plt.figure()\tax = Axes3D(fig)\tax.plot_surface(x, z, y, cmap=&#x27;rainbow&#x27;)\tplt.show()def show_scatter_surface(xs,y,forward_propgation):\tx = xs[:,0]\tz = xs[:,1]\tfig = plt.figure()\tax = Axes3D(fig)\tax.scatter(x, z, y)\tx = np.arange(np.min(x),np.max(x),0.01)\tz = np.arange(np.min(z),np.max(z),0.01)\tx,z = np.meshgrid(x,z)\ty = forward_propgation(x,z)\t\tax.plot_surface(x, z, y, cmap=&#x27;rainbow&#x27;)\tplt.show()\n\n而这次，为了展现多个输入的情况，产生数据集的函数也有所不同。\nimport numpy as npdef get_beans(counts):\txs = np.random.rand(counts,2)*2\tys = np.zeros(counts)\tfor i in range(counts):\t\tx = xs[i]\t\tif (x[0]-0.5*x[1]-0.1)&gt;0:\t\t\tys[i] = 1\treturn xs,ysdef get_beans2(counts):\txs = np.random.rand(counts,2)*2\tys = np.zeros(counts)\tfor i in range(counts):\t\tx = xs[i]\t\tif (np.power(x[0]-1,2)+np.power(x[1]-0.3,2))&lt;0.5:\t\t\tys[i] = 1\treturn xs,ys\n\n它会产生一个两列的数组。可以使用numpy库的特性分割开得到两组输入。\nx1s = xs[:,0]#切割第0列形成一个新的数组x2s = xs[:,1]\n\n再将前向传播封装为一个函数：\ndef forward(x1s,x2s):\tz = w1*x1s + w2*x2s + b\ta = 1/(1+np.exp(-z))\treturn a\n\n最后，依旧利用反向传播与梯度下降算法进行学习拟合。\nfor _ in range(500):\tfor i in range(m):\t\tx = xs[i]\t\ty = ys[i]\t\tx1 = x[0]\t\tx2 = x[1]\t\ta = forward(x1,x2)\t\te = (y-a)**2\t\tdeda = -2*(y-a)\t\tdadz = a*(1-a)\t\tdzdw1 = x1\t\tdzdw2 = x2\t\tdzdb = 1\t\tdedw1 = deda*dadz*dzdw1\t\tdedw2 = deda*dadz*dzdw2\t\tdedb = deda*dadz*dzdb\t\talpha = 0.01\t\tw1 = w1 - alpha*dedw1\t\tw2 = w2 - alpha*dedw2\t\tb = b - alpha*dedb\n\n最后我们可以得到这样的结果：\n\n如果我们从另一个角度来看的话，它就和添加了激活函数后的最简单的Rosenblatt感知器模型得到的结果类似：\n\n输入数据的增加会导致维度增加，但最为三维生物我们无法具象化三维以上的模型，但对于计算机来说，增加一个输入就是增加一维数组，这样高维空间的学习与计算对他来说也可以实现\n","categories":["AIlearning"],"tags":["AI"]},{"title":"隐藏层与深度学习","url":"/2022/01/03/%E9%9A%90%E8%97%8F%E5%B1%82%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/","content":"在现实中，判断一个物体，或者说对一个物体下定义，往往不能只从一个方面或两个方面观察。这时候，单个的Rosenblatt感知器已经无法胜任这样复杂的判断，是时候再增加一个神经元了。新增一个神经元，便增加了一个抽象的维度，每个维度通过不断地调整权重并进行激活，从而产生对输入的不同理解，最后再将这些抽象维度中的输出合并并降维得到最后的输出。而这些新添加的神经元，就被称之为隐藏层。\n为了直观的看到效果，我还是使用了matplotlib进行绘图。这一次的w和b的值，我选择使用rand()函数生成随机数。并且为了之后的方便，将sigmoid函数（标准Logistic函数）和前向传播封装为两个函数。\nimport datasetimport matplotlib.pyplot as pltimport numpy as npm = 100xs, ys = dataset.get_beans(m)plt.title(&quot;STF&quot;, fontsize=12)plt.xlabel(&quot;B&quot;)plt.ylabel(&quot;T&quot;)plt.scatter(xs, ys)def sigmoid(x):\treturn 1/(1+np.exp(-x))#第一层#第一个神经元w11_1 = np.random.rand()b1_1 = np.random.rand()#第二个神经元w12_1 = np.random.rand()b2_1 = np.random.rand()#第二层w11_2 = np.random.rand()w21_2 = np.random.rand()b1_2 = np.random.rand()#前向传播def forward(xs):\t#第一层第一个\tz1_1 = w11_1*xs + b1_1\ta1_1 = sigmoid(z1_1)\t#第一层第二个\tz2_1 = w12_1*xs + b2_1\ta2_1 = sigmoid(z2_1)\t#第二层（输出层）\tz1_2 = w11_2*a1_1 + w21_2*a2_1 + b1_2\ta1_2 = sigmoid(z1_2)\treturn a1_2,z1_2,a2_1,z2_1,a1_1,z1_1\n\n这样准备工作就完成了，接下来就是繁琐的隐藏层求导进行反向传播的过程。\nfor _ in range(5000):\tfor i in range(100):\t\tx = xs[i]\t\ty = ys[i]\t\t#先来一次前向传播\t\ta1_2,z1_2,a2_1,z2_1,a1_1,z1_1 = forward(x)\t\t#反向传播\t\t#代价函数e\t\te = (y-a1_2)**2\t\tdeda1_2 = -2*(y - a1_2)\t\tda1_2dz1_2 = a1_2*(1 - a1_2)\t\tdz1_2dw11_2 = a1_1\t\tdz1_2dw21_2 = a2_1\t\tdedw11_2 = deda1_2*da1_2dz1_2*dz1_2dw11_2\t\tdedw21_2 = deda1_2*da1_2dz1_2*dz1_2dw21_2\t\tdz1_2db1_2 = 1\t\tdedb1_2 = deda1_2*da1_2dz1_2*dz1_2db1_2\t\t#隐藏层的第一个神经元\t\tdz1_2da1_1 = w11_2\t\tda1_1dz1_1 = a1_1*(1-a1_1)\t\tdz1_1dw11_1 = x\t\tdedw11_1 = deda1_2*da1_2dz1_2*dz1_2da1_1*da1_1dz1_1*dz1_1dw11_1\t\tdz1_1db1_1 = 1\t\tdedb1_1 = deda1_2*da1_2dz1_2*dz1_2da1_1*da1_1dz1_1*dz1_1db1_1\t\t#隐藏层的第二个神经元\t\tdz1_2da2_1 = w21_2\t\tda2_1dz2_1 = a2_1*(1-a2_1)\t\tdz2_1dw12_1 = x\t\tdedw12_1 = deda1_2*da1_2dz1_2*dz1_2da2_1*da2_1dz2_1*dz2_1dw12_1\t\tdz2_1db2_1 = 1\t\tdedb2_1 = deda1_2*da1_2dz1_2*dz1_2da2_1*da2_1dz2_1*dz2_1db2_1\t\t#梯度下降\t\talpha = 0.03\t\tw11_2 = w11_2 - alpha*dedw11_2\t\tw21_2 = w21_2 - alpha*dedw21_2\t\tb1_2 = b1_2 - alpha*dedb1_2\t\tw12_1 = w12_1 - alpha*dedw12_1\t\tb2_1 = b2_1 - alpha*dedb2_1\t\tw11_1 = w11_1 - alpha*dedw11_1\t\tb1_1 = b1_1 - alpha*dedb1_1\n\n经过漫长的求导与修改错误，最后再使用plt.clf()函数和plt.pause()函数相结合绘制动态图像，就得到了最终的结果。\n\n当隐藏层变得更多与更深，神经网络也会变得更加强大与智能。当我们设计出一个复杂程度恰当的神经网络，经过不断的训练过后，网络中的各个参数被调节成不同的值，而他们组成的整体，就可以近似出一个相当复杂的函数。\n我们一般把隐藏层超过三层的网络称之为深度神经网络。隐藏层的神经元对样本的理解和提取的参数都太过微妙，我们能做的也只有设计一个网络，送入数据进行训练，如果效果好，那它就”起作用了“，效果不好就”没起作用“，只能再次调参，再来一次。这也是为什么深度学习被很多人戏称”炼丹“的原因。\n","categories":["AIlearning"],"tags":["AI"]},{"title":"自然语言处理（NLP）——LSTM网络","url":"/2022/01/09/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88NLP%EF%BC%89%E2%80%94%E2%80%94LSTM%E7%BD%91%E7%BB%9C/","content":"使用全连接神经网络来处理自然语言未免有些乏力，之前也可以看出准确率并不是很高，这时候就需要另一种专为NLP而生的网络——LSTM网络（长短时记忆网络）。\n想要学习这个网络，得先从RNN看起。循环神经网络（Recurrent Neural Network，RNN）是一种用于处理序列数据的神经网络。相比一般的神经网络来说，他能够处理序列变化的数据。它的激活函数多采用双曲正切函数tanh而不是relu，当然也可以使用relu。而为了每一步操作的统一性，在第一步时会手动添加一个共同输入a0，比如一个全0向量。\n而完全体的LSTM是比较复杂的\n\n首先LSTM结构中的输出再次经过一个tanh函数，而原先的输出，就变成了一个叫做细胞状态（Ct）的东西，这个细胞状态就是LSTM能应对长依赖问题的关键，它就能让网络具有记忆和遗忘的效果。为了实现这个效果，LSTM使用了两个门来实现。第一个是遗忘门（forget gate）。使用一个sigmoid层，使其与上个细胞状态值相乘。当sigmoid为0时，就相当于把上个细胞值完全丢弃，即忘记。反之则全部记忆。而这个sigmoid层的输入则是本次词向量与上一次的输出合并的数据，这样就可以通过本次与之前的数据共同决定忘记多少之前的细胞值。第二个是更新门（update gate）。让本次的词向量与上一此的输出合并的数据在经过一个sigmoid层形成控制这个在之前标准RNN结构中用来更新的部分，即用来控制是否更新本次细胞状态值。这样就实现了记忆和遗忘的效果。而最后还有一个输出门，在标准RNN结构最后的输出也乘一个sigmoid层，这样在遇到重要词汇时产生强输出，使其难以遗忘，反之亦然。\n当然这只是对LSTM的及其粗略的讲解，这篇博客有着更加详细的讲解，还有LSTM变种结构比如GRU的介绍。\nhttps://colah.github.io/posts/2015-08-Understanding-LSTMs/\n之后就是利用LSTM对之前的网购评论数据进行学习了。\n我在GitHub上找到了一个训练好的中文词向量\nhttps://github.com/Embedding/Chinese-Word-Vectors\n利用这个词向量来训练LSTM网络\n首先封装一个能读取这个词向量文件的chinese_vec.py\nimport osimport numpy as npdef load_word_vecs():\tembeddings_index = &#123;&#125;\tf = open(os.path.dirname(os.path.abspath(__file__))+&#x27;/sgns.target.word-word.dynwin5.thr10.neg5.dim300.iter5&#x27;,encoding=&#x27;utf8&#x27;)\tf.readline()#escape first line\tfor line in f:\t    values = line.split()\t    word = values[0]\t    coefs = np.asarray(values[1:], dtype=&#x27;float32&#x27;)\t    embeddings_index[word] = coefs\tf.close()\tprint(&#x27;Found %s word vectors.&#x27; % len(embeddings_index))\treturn embeddings_index\n\n然后调用它读取，在经过判断是否存在后写入一个空数组。\nword_vecs = chinese_vec.load_word_vecs()embedding_matrix = np.zeros((vocalen, 300))for word, i in word_index.items():\tembedding_vector = word_vecs.get(word)\tif embedding_vector is not None:\t\tembedding_matrix[i] = embedding_vector\n\n然后就是构造LSTM，使用Keras可以十分简单\nmodel = Sequential()model.add(Embedding(trainable=False, weights=[embedding_matrix], input_dim=vocalen, output_dim=300, input_length=maxlen))model.add(LSTM(128, return_sequences=True))model.add(LSTM(128))\n\n之后就可以开始训练了。最后可以得到一个接近90%的准确率\n\n","categories":["AIlearning"],"tags":["AI"]},{"url":"/2025/01/05/1/","content":"\n","categories":["Pic"],"tags":["Presented by Miv4t"]},{"title":"Word2Vec在NLP中的应用","url":"/2023/09/26/Word2Vec%E5%9C%A8NLP%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/","content":"什么是Word2Vec","categories":["AIlearning"],"tags":["AI"]},{"url":"/2023/12/18/Web%E6%B8%97%E9%80%8F%E5%B7%A5%E5%85%B7%E9%9B%86/","content":"Web渗透综合扫描类1.外网\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nafrog\nhttps://github.com/zan8in/afrog\nafrog 是一款快速、稳定的高性能漏洞扫描器。\n\n\nxray\nhttps://github.com/chaitin/xray\n一款完善的安全评估工具，支持常见 web 安全问题扫描\n\n\nnuclei\nhttps://github.com/projectdiscovery/nuclei\nNuclei使用零误报的定制模板对主机进行批量快速扫描。\n\n\nnacs\nhttps://github.com/u21h2/nacs\n事件驱动的渗透测试扫描器\n\n\npocsuite3\nhttps://github.com/knownsec/pocsuite3\npocsuite3是由知道创宇404团队开发的开源远程漏洞测试框架。\n\n\nscan4all\nhttps://github.com/GhostTroops/scan4all\n集成 vscan、nuclei、ksubdomain、subfinder进行扫描\n\n\ngoon\nhttps://github.com/i11us0ry/goon\ngoon,集合了fscan和kscan等优秀工具功能的扫描爆破工具。\n\n\nvscan\nhttps://github.com/veo/vscan\n开源、轻量、快速、跨平台 的网站漏洞扫描工具，帮助您快速检测网站安全隐患。\n\n\nRailgun\nhttps://github.com/lz520520/railgun\nRailgun为一款GUI界面的渗透工具，目前集成了端口扫描、端口爆破、web指纹扫描、漏洞扫描、漏洞利用以及编码转换功能，后续会持续更新。\n\n\nyakit\nhttps://github.com/yaklang/yakit\n单兵作战神器\n\n\ngoby\nhttps://gobysec.net/\n新一代网络安全技术，通过为目标建立完整的资产数据库，实现快速的安全应急。\n\n\nPOC-bomber\nhttps://github.com/tr0uble-mAker/POC-bomber\n利用大量高威胁poc&#x2F;exp快速获取目标权限，用于渗透和红队快速打点\n\n\nvulmap\nhttps://github.com/zhzyker/vulmap\nVulmap 是一款 web 漏洞扫描和验证工具\n\n\nkscan\nhttps://github.com/lcvvvv/kscan\nKscan是一款纯go开发的全方位扫描器，具备端口扫描、协议检测、指纹识别，暴力破解等功能。\n\n\n2.内网\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nfscan\nhttps://github.com/shadow1ng/fscan\n一款内网综合扫描工具，方便一键自动化、全方位漏扫扫描。\n\n\nTemplate\nhttps://github.com/1n7erface/Template\n下一代RedTeam启发式内网扫描\n\n\nSweetBabyScan\nhttps://github.com/inbug-team/SweetBabyScan\n轻量级内网资产探测漏洞扫描工具\n\n\nFvuln\nhttps://github.com/d3ckx1/Fvuln\nF-vuln是为了自己工作方便专门编写的一款自动化工具\n\n\ndismap\nhttps://github.com/zhzyker/dismap\n快速识别 Web 指纹信息，定位资产类型。\n\n\n信息搜集类指纹扫描\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nTideFinger_Go\nhttps://github.com/TideSec/TideFinger_Go\nTideFinger指纹识别工具，可对web和主机指纹进行识别探测\n\n\nEhole\nhttps://github.com/EdgeSecurityTeam/EHole\nEHole(棱洞)3.0 重构版-红队重点攻击系统指纹探测工具\n\n\nFinder\nhttps://github.com/EASY233/Finger\n一款红队在大量的资产中存活探测与重点攻击系统指纹探测工具\n\n\n潮汐指纹识别\nhttp://finger.tidesec.net/\n潮汐指纹识别\n\n\nWhatWeb\nhttps://github.com/urbanadventurer/WhatWeb\n网站指纹识别工具\n\n\ncdncheck\nhttps://github.com/projectdiscovery/cdncheck\n一款用于渗透中检测网站CDN&#x2F;WAF&#x2F;云的工具\n\n\n资产发现\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nARL\nhttps://github.com/TophantTechnology/ARL\nARL资产侦察灯塔系统旨在快速侦察与目标关联的互联网资产，构建基础资产信息库。\n\n\nARL-Finder-ADD\nhttps://github.com/loecho-sec/ARL-Finger-ADD\n灯塔（最新版）指纹添加脚本！\n\n\nfofa_viewer\nhttps://github.com/wgpsec/fofa_viewer\nFofa Viewer 是一个用 JavaFX 编写的用户友好的 FOFA 客户端\n\n\nThunderSearch\nhttps://github.com/xzajyjs/ThunderSearch\n支持Fofa、Shodan、Hunter、Zoomeye、Quake网络空间搜索引擎】闪电搜索器\n\n\nENScan_GO\nhttps://github.com/wgpsec/ENScan_GO\n一款基于各大企业信息API的工具，解决在遇到的各种针对国内企业信息收集难题\n\n\nfofax\nhttps://github.com/xiecat/fofax\nfofax是一款基于API的命令行查询工具\n\n\nfofaEX\nhttps://github.com/10cks/fofaEX\n基于 FOFA 的 java 客户端&#x2F;红队工具\n\n\nnemo_go\nhttps://github.com/hanc00l/nemo_go\nNemo是用来进行自动化信息收集的一个简单平台\n\n\nShuiZe\nhttps://github.com/0x727/ShuiZe_0x727\n信息收集自动化工具\n\n\nGoogle 搜索语法生成器\nhttp://www.php1nf0.top/google/google.php\nGoogle 搜索语法生成器\n\n\n子域名收集\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nLayer\nhttps://github.com/euphrat1ca/LayerDomainFinder\nLayer子域名挖掘机\n\n\nOneForAll\nhttps://github.com/shmilylty/OneForAll\nOneForAll是一款功能强大的子域收集工具\n\n\nsubdomain\nhttps://rapiddns.io/subdomain\n在线子域名爆破工具\n\n\nsubfinder\nhttps://github.com/projectdiscovery/subfinder\n快速被动子域枚举工具\n\n\ndnsub\nhttps://github.com/yunxu1/dnsub\ndnsub一款好用且强大的子域名扫描工具\n\n\n在线-子域名爆破\nhttp://z.zcjun.com/\n二级域名挖掘\n\n\nHosts_scan\nhttps://github.com/fofapro/Hosts_scan\n一个用于IP和域名碰撞匹配访问的小工具\n\n\nhostscan\nhttps://github.com/cckuailong/hostscan\n自动化Host碰撞工具，帮助红队快速扩展网络边界，获取更多目标点\n\n\n目录扫描\n\n\n工具名称\n下载地址\n工具描述\n\n\n\ndirsearch\nhttps://github.com/maurosoria/dirsearch\n目录扫描\n\n\ndirsearch_bypass403\nhttps://github.com/lemonlove7/dirsearch_bypass403\n目录扫描+JS文件中提取URL和子域+403状态绕过+指纹识别\n\n\nferoxbuster\nhttps://github.com/epi052/feroxbuster\n递归目录扫描\n\n\ngobuster\nhttps://github.com/OJ/gobuster\n基于go的快读目录扫描工具\n\n\nffuf\nhttps://github.com/ffuf/ffuf\n模糊性测试，目录爆破工具\n\n\n御剑后台扫描工具珍藏版\nhttps://www.fujieace.com/hacker/tools/yujian.html\n图形化界面版爆破工具\n\n\ndirb\nkali自带\n目录扫描\n\n\nihoneyBakFileScan_Modify\nhttps://github.com/VMsec/ihoneyBakFileScan_Modify\n备份文件扫描器\n\n\n端口扫描\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nnmap\nhttps://nmap.org/download\n全能型扫描端口神器\n\n\nnaabu\nhttps://github.com/projectdiscovery/naabu\n用 Go 编写的快速端口扫描器，专注于可靠性和简单性。\n\n\nTXPortMap\nhttps://github.com/4dogs-cn/TXPortMap\n端口扫描工具\n\n\nmasscan\nhttps://github.com/robertdavidgraham/masscan\n速度号称最快的端口扫描工具\n\n\nscaninfo\nhttps://github.com/redtoolskobe/scaninfo\n快速扫描端口工具\n\n\n在线扫描端口工具1\nhttp://coolaf.com/tool/port\n在线扫描端口1\n\n\n在线扫描端口工具2\nhttps://tool.cc/port/\n在线扫描端口2\n\n\nBurp插件\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nTsojanScan\nhttps://github.com/Tsojan/TsojanScan\n一个集成的BurpSuite漏洞探测插件\n\n\nShiroScan\nhttps://github.com/sv3nbeast/ShiroScan\nShiro&lt;&#x3D;1.2.4反序列化，一键检测工具\n\n\nFastjsonScan\nhttps://github.com/a1phaboy/FastjsonScan\nFastjson扫描器，可识别版本、依赖库、autoType状态等\n\n\nknife\nhttps://github.com/bit4woo/knife\n添加一些右键菜单让burp用起来更顺畅\n\n\nHaE\nhttps://github.com/gh0stkey/HaE\nHaE 请求高亮标记与信息提取的辅助型 BurpSuite 插件\n\n\ncaptcha-killer-modified\nhttps://github.com/f0ng/captcha-killer-modified\n验证码识别\n\n\nBurpCrypto\nhttps://github.com/whwlsfb/BurpCrypto\n支持多种加密算法或直接执行JS代码的用于爆破前端加密的BurpSuite插件\n\n\nautoDecoder\nhttps://github.com/f0ng/autoDecoder\nBurp插件，根据自定义来达到对数据包的处理（适用于加解密、爆破等）\n\n\nAutoRepeater\nhttps://github.com/nccgroup/AutoRepeater\n自动发送请求\n\n\njsEncrypter\nhttps://github.com/c0ny1/jsEncrypter\n一个用于前端加密Fuzz的Burp Suite插件\n\n\nAPIKit\nhttps://github.com/API-Security/APIKit\n可以主动&#x2F;被动扫描发现应用泄露的API文档\n\n\nRouteVulScan\nhttps://github.com/F6JO/RouteVulScan\n递归式被动检测脆弱路径的burp插件\n\n\njson-web-tokens\nhttps://github.com/portswigger/json-web-tokens（burp商店可下载）\nJWT测试\n\n\nLog4j2Scan\nhttps://github.com/whwlsfb/Log4j2Scan\n被动扫描Log4j2漏洞CVE-2021-44228的BurpSuite插件\n\n\nburp-awesome-tls\nhttps://github.com/sleeyax/burp-awesome-tls\n绕过WAF，欺骗任何浏览器。\n\n\nViewStateDecoder\nhttps://github.com/raise-isayan/ViewStateDecoder\nBurpsuite 扩展。支持 ASP.NET ViewStateDecoder\n\n\nchunked-coding-converter\nhttps://github.com/c0ny1/chunked-coding-converter\n添加脏数据和延时分块传输\n\n\nxia_sql\nhttps://github.com/smxiazi/xia_sql\nxia SQL (瞎注) burp 插件 ，在每个参数后面填加一个单引号，两个单引号，一个简单的判断注入小插件。\n\n\n浏览器插件\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nSwitchyOmega\nhttps://github.com/FelisCatus/SwitchyOmega（扩展商店自行下载）\nSwitchyOmega 浏览器的代理插件\n\n\nheimdallr\n扩展商店自行下载\n检测蜜罐网站\n\n\nmulti-elasticsearch-head\n扩展商店自行下载\n连接elasticsearch\n\n\nFindSomething\n扩展商店自行下载\n网页源代码进行搜集敏感信息\n\n\nX-Forwarded-For Header\n扩展商店自行下载\n添加xff头\n\n\nWappalyzer\n扩展商店自行下载\n识别网站特征\n\n\nUser-Agent Switcher and Manager\n扩展商店自行下载\n修改网站UA头\n\n\nuBlock Origin Lite\n扩展商店自行下载\n防止弹窗，垃圾广告等\n\n\nCookie-Editor\n扩展商店自行下载\n伪造cookie\n\n\nHackerBar\nhttps://github.com/HackerBar-Sec/HackerBar\n一款匿名的资产查询工具\n\n\nHackbar\n由于版本收费，需自行获取！\nHackBar 是一种安全审计工具，可让您更轻松地对网站进行渗透测试\n\n\nsuperSearchPlus\nhttps://github.com/dark-kingA/superSearchPlus\n聚合型信息收集插件，支持综合查询，资产测绘查询，信息收集 敏感信息提取 js资源扫描 目录扫描 vue组件扫描\n\n\n钓鱼平台\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nswaks\nhttps://github.com/jetmore/swaks（kali自带）\nSwaks 是一个功能强大、灵活、可编写脚本、面向事务的 SMTP 测试工具\n\n\ngophish\nhttps://github.com/gophish/gophish\n可以自行在线模板、发送诱骗广告等功能的钓鱼系统\n\n\nmip22\nhttps://github.com/makdosx/mip22\nMIP22 是一种高级网络钓鱼工具 ，拥有83种钓鱼自带页面\n\n\nSocialFish\nhttps://github.com/UndeadSec/SocialFish\n强大的钓鱼工具\n\n\n漏洞利用类综合漏洞扫描工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nHyacinth\nhttps://github.com/pureqh/Hyacinth\n一款java漏洞集合工具\n\n\nNaturalTeeth\nhttps://github.com/ddwGeGe/NaturalTeeth\n一款漏洞利用小工具\n\n\n0Day_2023\nhttps://github.com/SunSkyZRT/2023HW-0Day-vulnerability-detection\n2023HWPoc利用工具\n\n\nApt_t00ls\nhttps://github.com/White-hua/Apt_t00ls\n高危漏洞利用工具\n\n\nOA-EXPTOOL\nhttps://github.com/LittleBear4/OA-EXPTOOL\nOA综合利用工具，集合将近20款OA漏洞批量扫描\n\n\nMYExploit\nhttps://github.com/achuna33/MYExploit\nOAExploit一款基于产品的一键扫描工具。\n\n\n用友NC系列漏洞检测利用工具\nhttps://github.com/wgpsec/YongYouNcTool/\n用友NC系列漏洞检测利用工具，支持一键检测、命令执行回显、文件落地、一键打入内存马、文件读取等\n\n\nLiqunKit\n需自行获取，暂不提供链接\n一款漏洞利用工具\n\n\nIngram\nhttps://github.com/jorhelp/Ingram\n网络摄像头漏洞扫描工具\n\n\n中间件&#x2F;应用&#x2F;接口漏洞利用工具\n\n\n漏洞组件\n工具名称\n下载地址\n工具描述\n\n\n\nApache\nApache_Penetration_Tool\nhttps://github.com/wangfly-me/Apache_Penetration_Tool\nCVE-2021-41773&amp;CVE-2021-42013图形化漏洞检测利用工具\n\n\nApereo CAS\nCas_Exploit\nhttps://gitee.com/keyboxdzd/Cas_Exploit\n4.1.X和4.2.X存在反序列化漏洞\n\n\nApache Dubbo\ndubbo扫描工具\nhttps://github.com/YYHYlh/Dubbo-Scan\nApache Dubbo 漏洞检测工具\n\n\nGeoServer\nGeoServer sql注入漏洞\nhttps://github.com/win3zz/CVE-2023-25157\nsql注入漏洞 CVE-2023-25157\n\n\ngitlab\ngitlab任意文件读取\nhttps://github.com/thewhiteh4t/cve-2020-10977\nGitLab 12.9.0 Arbitrary File Read\n\n\ngitlab远程命令执行\nhttps://github.com/Al1ex/CVE-2021-22205\nCVE-2021-22205\n\n\n\njboss\njboss反序列化工具\nhttps://github.com/s0k/Deserialize\njboss反序列化工具\n\n\n未授权&#x2F;弱口令检测\nhttps://github.com/rambleZzz/jmxbfGUI\n未授权&#x2F;弱口令检测\n\n\n\njboss漏洞检测工具\nhttps://github.com/Ye4r/JbossExploit\njboss漏洞检测工具\n\n\n\nJenkins\nJenkins 远程代码执行漏洞\nhttps://github.com/vulhub/CVE-2017-1000353/\nCVE-2017-1000353 （远程代码执行）\n\n\nJenkins 远程代码执行漏洞\nhttps://github.com/orangetw/awesome-jenkins-rce-2019\nCVE-2018-1000861（远程代码执行）\n\n\n\nminio\n敏感信息泄露\nhttps://github.com/MzzdToT/CVE-2023-28432\n敏感信息泄露\n\n\nnacos\n综合利用工具\nhttps://github.com/charonlight/NacosExploitGUI\n综合利用工具\n\n\n反序列化工具\nhttps://github.com/c0olw/NacosRce\n反序列化工具\n\n\n\nApache RocketMQ\n远程漏洞执行\nhttps://github.com/SuperZero/CVE-2023-33246\nCVE-2023-33246\n\n\nshiro\nshiro550工具\nhttps://github.com/j1anFen/shiro_attack\nshiro550\n\n\nhttps://github.com/SummerSec/ShiroAttack2\n\n\n\n\n\nhttps://www.aliyundrive.com/s/ALnnGVKfFT9\n\n\n\n\n\nhttps://github.com/feihong-cs/ShiroExploit-Deprecated/\n\n\n\n\n\nspringboot\nSpringExploit\nhttps://github.com/SummerSec/SpringExploit\n综合利用工具\n\n\nspring gateway远程执行代码\nhttps://github.com/SummerSec\n内存马大杀器（CVE-2022-22947）\n\n\n\nSBSCAN\nhttps://github.com/sule01u/SBSCAN\nSBSCAN是一款专注于spring框架的渗透测试工具\n\n\n\nthinkphp\n利用工具\nhttps://github.com/zangcc/Aazhen-RexHa\nthinkphp自动化检查器\n\n\nhttps://github.com/Lotus6/ThinkphpGUI\n\n\n\n\n\nhttps://github.com/safe6Sec/ThinkPHPLogScan\n\n\n\n\n\nhttps://github.com/bewhale/thinkphp_gui_tools\n\n\n\n\n\ntomcat\nApacheTomcatScanner\nhttps://github.com/p0dalirius/ApacheTomcatScanner\ntomcat测试工具\n\n\nVcenter\nVcenterKiller\nhttps://github.com/Schira4396/VcenterKiller\n一款针对Vcenter的综合利用工具\n\n\nVcenterKit\nhttps://github.com/W01fh4cker/VcenterKit\nVcenter综合渗透利用工具包\n\n\n\nWeblogic\nWeblogicTool\nhttps://github.com/KimJun1010/WeblogicTool\nWeblogicTool，GUI漏洞利用工具\n\n\nWeblogicExploit-GUI\nhttps://github.com/sp4zcmd/WeblogicExploit-GUI\nWeblogic漏洞利用图形化工具\n\n\n\nwebpack\nPacker-Fuzzer-Plus\nhttps://github.com/BigYoungs/Packer-Fuzzer-Plus\n一款针对Webpack等前端打包工具所构造的网站进行快速、高效安全检测的扫描工具\n\n\nPacker-Fuzzer\nhttps://github.com/rtcatc/Packer-Fuzzer\n一款针对Webpack等前端打包工具所构造的网站进行快速、高效安全检测的扫描工具\n\n\n\nURLFinder\nhttps://github.com/pingc0y/URLFinder\n全面提取网站页面的接口\n\n\n\nwordpress\nwpscan\nkali里自带\nwordpress扫描神器\n\n\nwsdl\nSoapUI\nhttps://www.soapui.org/\n接口测试神器\n\n\nwsdler\nburp商店下载\n接口测试\n\n\n\nReadyAPI\n自行获取\n接口测试\n\n\n\nK8s\nk8sUnauthorizedAccessScanner\nhttps://github.com/b0bac/k8sUnauthorizedAccessScanner\nkubernetes未授权访问漏洞扫描\n\n\nredis\nRedisWriteFile\nhttps://github.com/r35tart/RedisWriteFile\n通过 Redis 主从写出无损文件\n\n\nredis-dump-go\nhttps://github.com/yannh/redis-dump-go\n备份和恢复Redis服务器 - FAST\n\n\n\nApache Solr\nsolr_rce\nhttps://github.com/jas502n/solr_rce\nSolr RCE  利用工具\n\n\n信息泄露利用工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nAliyun-.AK.Tools\nhttps://github.com/mrknow001/aliyun-accesskey-Tools\n阿里云accesskey利用工具（图形界面）\n\n\ncf\n需自行获取，暂不提供下载\n云资产利用工具\n\n\ncloudTools\nhttps://github.com/dark-kingA/cloudTools\n云资产管理工具 目前工具定位是云安全相关工具\n\n\nAPI-T00L\nhttps://github.com/pykiller/API-T00L\n飞书，钉钉，企业微信api接口利用\n\n\nAPI-Explorer\nhttps://github.com/mrknow001/API-Explorer\n小程序、公众号、企业微信、飞书、钉钉等泄露secert后利用工具\n\n\noss-stinger\nhttps://github.com/9bie/oss-stinger\n利用腾讯云oss，来转发http流量可以用来cs&#x2F;msf上线等\n\n\nGitHack\nhttps://github.com/lijiejie/GitHack\nGitHack是一个.git泄露利用脚本，通过泄露的.git文件夹下的文件，重建还原工程源代码\n\n\nheapdump_tool\nhttps://www.aliyundrive.com/s/GapNjP3a9Rx\n敏感信息查询工具\n\n\nJDumpSpider-1.0-SNAPSHOT-full\nhttps://github.com/whwlsfb/JDumpSpider\nHeapDump敏感信息提取工具\n\n\nswagger-exp\nhttps://github.com/lijiejie/swagger-exp\n尝试swagger所有接口\n\n\nswagger-hack\nhttps://github.com/jayus0821/swagger-hack\n自动化爬取并自动测试所有swagger接口\n\n\nds_store_exp\nhttps://github.com/lijiejie/ds_store_exp\n.DS_store文件泄露利用工具\n\n\ndvcs-ripper\nhttps://github.com/kost/dvcs-ripper.git\n.cvs源代码泄露利用工具\n\n\nsvnExploit\nhttps://github.com/admintony/svnExploit\nSvnExploit支持SVN源代码泄露全版本Dump源码\n\n\ngit-dumper\nhttps://github.com/arthaud/git-dumper\ngit-dumper 从网站转储git存储库的工具\n\n\ndumpall\nhttps://github.com/0xHJK/dumpall\n一款信息泄漏利用工具，适用于.git&#x2F;.svn&#x2F;.DS_Store泄漏和目录列出\n\n\nbadsecrets\nhttps://github.com/blacklanternsecurity/badsecrets\n用于检测多个 Web 框架中的已知机密的库 例如 JWT  Viewstate    Django_SignedCookies\n\n\n数据库利用工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nMDUT\nhttps://github.com/SafeGroceryStore/MDUT\nMDUT 数据库利用工具\n\n\nDatabasetools\nhttps://github.com/Hel10-Web/Databasetools\n一款用Go语言编写的数据库自动化提权工具\n\n\nSharpSQLTools\nhttps://github.com/uknowsec/SharpSQLTools\nsqlserver利用工具\n\n\nmssqlproxy\nhttps://github.com/blackarrowsec/mssqlproxy\n通过套接字重用通过受损的 Microsoft SQL Server 在受限环境中执行横向移动\n\n\nODAT\nhttps://github.com/quentinhardy/odat\nODAT：Oracle 数据库攻击工具\n\n\nAnother Redis Desktop Manager\nhttps://goanother.com/cn/\nredis连接工具\n\n\nredis-rogue-getshell\nhttps://github.com/vulhub/redis-rogue-getshell\nredis主从复制工具\n\n\nRedisEXP\nhttps://github.com/yuyan-sec/RedisEXP\nredis命令利用工具\n\n\nLDAP Browser\nhttps://ldapbrowserwindows.com/\nldap连接\n\n\noracleshell\nhttps://github.com/jas502n/oracleShell\noracle 数据库命令执行  测试工具\n\n\nDataMiner\nhttps://github.com/wjlab/DataMiner/\n数据库自动取样工具\n\n\n社工&#x2F;常规字典制作&#x2F;收集\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nDictionary-Of-Pentesting\nhttps://github.com/insightglacier/Dictionary-Of-Pentesting\n渗透测试、SRC漏洞挖掘、爆破、Fuzzing等字典收集项目\n\n\nfuzzDicts\nhttps://github.com/TheKingOfDuck/fuzzDicts\n字典,一个就够了\n\n\nS-BlastingDictionary\nhttps://github.com/shadowabi/S-BlastingDictionary\n自己搜集的爆破字典，包括常用用户名、密码弱口令、SQL万能密码等\n\n\nSecLists\nhttps://github.com/danielmiessler/SecLists\n安全评估期间使用的多种类型列表的集合\n\n\nBaiLu-SED-Tool\nhttps://github.com/z3r023/BaiLu-SED-Tool\n白鹿社工字典生成器，灵活与易用兼顾。\n\n\nFdict\nhttps://github.com/ccc-f/Fdict\n一款面向企业的渗透测试字典生成工具。\n\n\nPwdBUD\nhttps://github.com/sry309/PwdBUD\n一款SRC密码生成工具，尝试top字典无果后，可以根据域名、公司名等因素来生成特定的字典\n\n\npydictor\nhttps://github.com/LandGrey/pydictor\n一个强大而有用的黑客字典构建器，用于暴力攻击\n\n\nSocialEngineeringDictionaryGenerator\nhttps://github.com/zgjx6/SocialEngineeringDictionaryGenerator\n社会工程学密码生成器，是一个利用个人信息生成密码的工具\n\n\nUserNameDictTools\nhttps://github.com/abc123info/UserNameDictTools/\n用户名密码字典生成工具(将中文汉字姓名转成14种格式的拼音\n\n\n常用漏洞利用工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nsqlmap\nhttps://github.com/sqlmapproject/sqlmap\nsql注入神器！没有之一\n\n\nCodex验证码后台爆破\nhttps://pan.baidu.com/s/112zaGL_-hlXsspKvzAn5Ug?pwd=32wb 提取码：32wb\n后台识别验证码爆破神器！\n\n\ntplmap\nhttps://github.com/epinna/tplmap\nSSTI模板注入测试\n\n\njwt_tool\nhttps://github.com/ticarpi/jwt_tool\n用于测试、调整和破解 JSON Web 令牌的工具包\n\n\njwt_hack\nhttps://github.com/hahwul/jwt-hack\njwt-hack 是用于对 JWT 进行黑客攻击&#x2F;安全测试的工具。\n\n\nblasting\nhttps://github.com/gubeihc/blasting\nweb前端爆破神器！自动识别验证码\n\n\nsslscan\nhttps://github.com/rbsec/sslscan\nsslscan 测试启用了 SSL&#x2F;TLS 的服务以发现支持的密码套件\n\n\ncheetah\nhttps://github.com/shmilylty/cheetah\ncheetah是一款基于字典的webshell密码爆破工具\n\n\nSmallProxyPool\nhttps://github.com/Ggasdfg321/SmallProxyPool\n一个免费高质量的小代理池，解决一些站点有WAF的情况下，进行目录扫描或者字典爆破\n\n\nGofreeproxy\nhttps://github.com/ja9er/Gofreeproxy\n动态代理小工具\n\n\n爆破利用工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nhydra\nkali自带 https://github.com/vanhauser-thc/thc-hydra\n爆破神器，什么都能爆\n\n\nhashcat\nhttps://github.com/hashcat/hashcat\n解hash，什么密码都会\n\n\njohn\nkali自带https://github.com/openwall/john\njohn 自己领会吧\n\n\nphpMyAdmin暴力破解\nhttps://github.com/kracer127/HackTools/tree/main/%E6%9A%B4%E5%8A%9B%E7%A0%B4%E8%A7%A3%E7%9B%B8%E5%85%B3\n专注于phpMyAdmin暴力破解\n\n\nAttackTomcat\nhttps://github.com/tpt11fb/AttackTomcat\nTomcat常见漏洞GUI利用工具  专注于tomcat弱口令爆破\n\n\n超级弱口令测试工具\nhttps://github.com/shack2/SNETCracker\n超级弱口令检查工具是一款Windows平台的弱口令审计工具\n\n\nPortBrute\nhttps://github.com/awake1t/PortBrute\n一款跨平台小巧的端口爆破工具，支持爆破FTP&#x2F;SSH&#x2F;SMB&#x2F;MSSQL&#x2F;MYSQL&#x2F;POSTGRESQL&#x2F;MONGOD\n\n\n反序列化利用工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nysuserial\nhttps://github.com/frohoff/ysoserial\n用于生成利用不安全的 Java 对象反序列化的有效负载\n\n\nJNDIExploit\nhttps://github.com/WhiteHSBG/JNDIExploit\n对ysuserial进行了修改，很强\n\n\nysuserial修改版\nhttps://github.com/Y4er/ysoserial\nysoserial修改版\n\n\nmarshalsec\nhttps://github.com/mbechler/marshalsec\njndi基础工具\n\n\n内存马注入工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nJundeadShell\nhttps://github.com/0x00007c00/JundeadShell\nJava内存马注入工具\n\n\nTomcatMemShell\nhttps://github.com/ce-automne/TomcatMemShell\n拿来即用的Tomcat7&#x2F;8&#x2F;9&#x2F;10版本Listener&#x2F;Filter&#x2F;Servlet内存马\n\n\nmsmap\nhttps://github.com/hosch3n/msmap\nMemory WebShell Generator\n\n\nRMI_Inj_MemShell\nhttps://github.com/novysodope/RMI_Inj_MemShell\nrmi打内存马工具，适用于目标用不了ldap的情况\n\n\nJavaAgentTools\nhttps://github.com/ethushiroha/JavaAgentTools\n用Java agent实现内存马等功能\n\n\nvagent\nhttps://github.com/veo/vagent\n多功能 java agent 内存马\n\n\n反连平台\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nrevsuit\nhttps://github.com/Li4n0/revsuit\nRevSuit 是一款灵活并且强大的反连平台。目前支持 HTTP、DNS、RMI、LDAP、MySQL 和 FTP 协议。\n\n\ndnslog\nhttp://dnslog.cn/\n在线反连平台\n\n\nCeye\nhttp://ceye.io/\n在线反连平台\n\n\nDigPm\nhttps://dig.pm/\n在线反连平台\n\n\n内网渗透类webshell管理&#x2F;插件工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nGodzilla\nhttps://github.com/BeichenDream/Godzilla\n哥斯拉\n\n\nBehinder\nhttps://github.com/rebeyond/Behinder\n“冰蝎”动态二进制加密网站管理客户端\n\n\nantSword\nhttps://github.com/AntSwordProject/antSword\n中国蚁剑是一款开源的跨平台网站管理工具\n\n\nCknife\nhttps://github.com/Chora10/Cknife\n跨平台版中国菜刀\n\n\nWebshell_Generate\nhttps://github.com/cseroad/Webshell_Generate\n用于生成各类免杀webshell\n\n\njava-memshell-generator\nhttps://github.com/pen4uin/java-memshell-generator-release\n一款支持高度自定义的 Java 内存马生成工具\n\n\nXG_NTAI\nhttps://github.com/xiaogang000/XG_NTAI\n一键免杀冰蝎、哥斯拉等webshell的php、jsp木马文件\n\n\nvshell\nhttps://github.com/veo/vshell\nvshell 是一款go编写的主机管理工具\n\n\n天蝎权限管理工具\nhttps://github.com/shack2/skyscorpion\n天蝎权限管理工具基于冰蝎加密流量进行WebShell通信管理\n\n\nas_bypass_php_disable_functions\nhttps://github.com/Medicean/as_bypass_php_disable_functions\nantsword bypass PHP disable_functions 蚁剑版\n\n\nas_plugin_godofhacker\nhttps://github.com/virink/as_plugin_godofhacker\n黑客神器，谁用谁知道！蚁剑版\n\n\nas_webshell_venom\nhttps://github.com/yzddmr6/as_webshell_venom\n免杀webshell无限生成工具蚁剑版\n\n\nAs-Exploits\nhttps://github.com/yzddmr6/As-Exploits\n中国蚁剑后渗透框架\n\n\ncodeExec\nhttps://github.com/1ucky7/GodzillaPluge-codeExec\nGodzilla插件|内存马|Suo5内存代理\n\n\nGodzillaPlugin-Suo5-MemProxy\nhttps://github.com/TonyNPham/GodzillaPlugin-Suo5-MemProxy\n一款高性能 HTTP 内存代理 | 哥斯拉插件 | readteam | 红队 | 内存马 | Suo5 | Godzilla | 正向代理\n\n\nMeterSphere-plugin-Backdoor\nhttps://github.com/wafinfo/MeterSphere-plugin-Backdoor\n支持注入内存马和Bypass WAF\n\n\nc2管理工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nC2ReverseProxy\nhttps://github.com/Daybr4ak/C2ReverseProxy\n一款可以在不出网的环境下进行反向代理及cs上线的工具\n\n\nhoaxshell\nhttps://github.com/t3l3machus/hoaxshell\n该工具易于使用，它生成自己的 PowerShell 有效负载并支持加密 (ssl)。\n\n\noss-stinger\nhttps://github.com/9bie/oss-stinger\n利用oss实现http转发&#x2F;cobalt strike上线\n\n\n提权项目\n\n\n工具名称\n下载地址\n工具描述\n\n\n\ntraitor\nhttps://github.com/liamg/traitor\nLinux自动提权\n\n\nhacking8\nhttps://i.hacking8.com/tiquan/\n在线提权建议\n\n\nPEASS-ng\nhttps://github.com/carlospolop/PEASS-ng\nPEASS-权限提升令人敬畏的脚本套件\n\n\nkernelpop\nhttps://github.com/spencerdodd/kernelpop\nkernel privilege escalation enumeration and exploitation framework\n\n\nlinux-exploit-suggester\nhttps://github.com/The-Z-Labs/linux-exploit-suggester\nLinux privilege escalation auditing tool\n\n\nwindows提权集合\nhttps://github.com/SecWiki/windows-kernel-exploits\nwindows-kernel-exploits Windows平台提权漏洞集合\n\n\nCoercedPotato\nhttps://github.com/hackvens/CoercedPotato\n通过在Windows 10、Windows 11和Server 2022上滥用SeImpersonatePrivilege特权可以从LOCAL&#x2F;NETWORK SERVICE提升为SYSTEM。\n\n\ndll_hijack\nhttps://github.com/JKme/sb_kiddie-/tree/master/hacking_win/dll_hijack\ndll劫持工具\n\n\n内网收集工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nnetspy\nhttps://github.com/shmilylty/netspy\n一款快速探测内网可达网段工具（深信服深蓝实验室天威战队强力驱动）\n\n\nsearchall\nhttps://github.com/Naturehi666/searchall\n强大的敏感信息搜索工具\n\n\nSharpHostInfo\nhttps://github.com/shmilylty/SharpHostInfo\nSharpHostInfo是一款快速探测内网主机信息工具\n\n\nLadon\nhttps://github.com/k8gege/Ladon\nLadon大型内网渗透工具\n\n\nPillager\nhttps://github.com/qwqdanchun/Pillager\nPillager是一个适用于后渗透期间的信息收集工具\n\n\n横向移动工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nimpacket\nhttps://github.com/fortra/impacket\n横向impacket工具包\n\n\nimpacket-gui\nhttps://github.com/yutianqaq/impacket-gui\n横向impacket工具包图形化\n\n\nwmiexec-Pro\nhttps://github.com/XiaoliChan/wmiexec-Pro\n基于impacket的免杀横向渗透远程命令执行工具（推荐）。\n\n\nWMIHACKER\nhttps://github.com/rootclay/WMIHACKER\nWMIHACKER是一款免杀横向渗透远程命令执行工具。\n\n\nOLa\nhttps://github.com/d3ckx1/OLa\ncs插件\n\n\nErebus\nhttps://github.com/DeEpinGh0st/Erebus\nCobaltStrike后渗透测试插件\n\n\nPoolPartyBof\nhttps://github.com/0xEr3bus/PoolPartyBof\ncs插件 进程注入\n\n\nPoolParty\nhttps://github.com/SafeBreach-Labs/PoolParty\n进程注入 exe版\n\n\nViper\nhttps://github.com/FunnyWolf/Viper\nRedteam operation platform with webui 图形化红队行动辅助平台\n\n\n域渗透工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nSchTask_0x727\nhttps://github.com/0x727/ShuiYing_0x727\n检测域环境内，域机器的本地管理组成员是否存在弱口令和通用口令，对域用户的权限分配以及域内委派查询\n\n\nBloodHoundBloodHound\nhttps://github.com/BloodHoundAD/BloodHound\n一个强大的内网域渗透分析工具\n\n\n密码提取工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nsearchall\nhttps://github.com/Naturehi666/searchall\n强大的敏感信息搜索工具\n\n\nmimikatz\nhttps://github.com/gentilkiwi/mimikatz\nMimikatz Windows 密码抓取神器\n\n\nSharpDecryptPwd\nhttps://github.com/RowTeam/SharpDecryptPwd\n用于读取常用程序密码，如Navicat、TeamViewer、FileZilla、WinSCP等\n\n\nSharpXDecrypt\nhttps://github.com/JDArmy/SharpXDecrypt\nXshell密码解密工具\n\n\nHackBrowserData\nhttps://github.com/moonD4rk/HackBrowserData/\n解密浏览器数据（密码|历史记录|Cookie|书签 | 信用卡 | 下载记录）的导出工具，支持全平台主流浏览器。\n\n\nTeamViewer\nhttps://github.com/wafinfo/TeamViewer\nTeamViewer：Bypass杀软 获取 Teamview 密码的工具\n\n\nSharpWxDump\nhttps://github.com/AdminTest0/SharpWxDump\n微信客户端取证，可获取用户个人信息(昵称&#x2F;账号&#x2F;手机&#x2F;邮箱&#x2F;数据库密钥(用来解密聊天记录))\n\n\nfakelogonscreen\nhttps://github.com/bitsadmin/fakelogonscreen\nFakeLogonScreen 是一个伪造 Windows 登录屏幕以获取用户密码的实用程序。\n\n\n隧道代理工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nproxifier\nhttps://www.proxifier.com/\n全平台代理工具，支持多种socks协议\n\n\nfrp\nhttps://github.com/fatedier/frp\n专注于内网穿透的高性能的反向代理应用\n\n\nnps\nhttps://github.com/ehang-io/nps\n轻量级、高性能、功能强大的内网穿透代理服务器\n\n\nNeo-reGeorg\nhttps://github.com/L-codes/Neo-reGeorg\n正向代理神器\n\n\new\nhttps://github.com/idlefire/ew\n代理神器\n\n\niox\nhttps://github.com/EddieIvan01/iox\nTool for port forwarding &amp; intranet proxy\n\n\nVenom\nhttps://github.com/Dliv3/Venom\nVenom - A Multi-hop Proxy for Penetration Testers\n\n\ngoproxy\nhttps://github.com/snail007/goproxy\ngoproxy 一款轻量级、功能强大、高性能的多种代理工具\n\n\nBounceBack\nhttps://github.com/D00Movenok/BounceBack\nBounceBack 是一个功能强大、高度可定制和可配置的反向代理，具有 WAF 功能，可将您的 C2&#x2F;网络钓鱼&#x2F;等基础设施隐藏起来\n\n\n免杀工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nBypassAntiVirus\nhttps://github.com/TideSec/BypassAntiVirus\n远控免杀系列文章及配套工具\n\n\nanti-av\nhttps://github.com/alphaSeclab/anti-av\n杀软和免杀有关的资料\n\n\nAV_Evasion_Tool\nhttps://github.com/1y0n/AV_Evasion_Tool\n掩日 - 免杀执行器生成工具\n\n\nScareCrow\nhttps://github.com/optiv/ScareCrow\n自动化生成 EDR 软件 Bypass Payload 的工具,一键化签名免杀\n\n\nAniYa\nhttps://github.com/piiperxyz/AniYa\n免杀框架\n\n\nshellcodeloader\nhttps://github.com/knownsec/shellcodeloader\nshellcode加载器\n\n\nThemida\n需要自己去找资源\n加壳工具\n\n\nSigThief\nhttps://github.com/secretsquirrel/SigThief\n签名工具\n\n\nShellQMaker\nhttps://github.com/SecurityAnalysts01/ShellcodeLoader/tree/1ff79fb9e1b9ad4934da88d9db82494d81a851c0\n超实用免杀\n\n\nRealBlindingEDR\nhttps://github.com/myzxcg/RealBlindingEDR\n利用带有签名驱动程序的任意地址读&#x2F;写实现：完全盲目或终止或永久关闭 AV&#x2F;EDR。\n\n\nQianji\nhttps://github.com/Pizz33/Qianji\n千机-红队免杀木马自动生成器\n\n\nCreateUser\nhttps://pan.quark.cn/s/7284c9c2c393#/list/share\n免杀360创建windows用户工具\n\n\nreshacker\n自行获取\n主要用于替换图标\n\n\nupx\nhttps://github.com/upx/upx\nUPX - 用于扩展的终极打包器\n\n\n维持权限工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nCobaltStrike_CNA\nhttps://github.com/yanghaoi/CobaltStrike_CNA\n使用多种WinAPI进行权限维持的CobaltStrike脚本\n\n\nHackerPermKeeper\nhttps://github.com/RuoJi6/HackerPermKeeper\nlinux权限维持工具\n\n\n数据恢复工具\n\n\n工具名称\n下载地址\n工具描述\n\n\n\nR-Studio\nhttps://pan.baidu.com/s/1gA-AtF2DJemFQepk-PZgSw?pwd=9gk4\nwindows数据恢复工具\n\n\n蓝队流量分析类\n\n\n工具名称\n下载地址\n工具描述\n\n\n\ntlsdump\nhttps://github.com/tlsdump/tlsdump\ndump 传输层安全数据，无需证书\n\n\n"}]